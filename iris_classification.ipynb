{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Flower Classification (Advanced)\n",
    "\n",
    "This notebook demonstrates classification of iris flower species using a variety of advanced machine learning models. We use the classic `Iris.csv` dataset and cover:\n",
    "\n",
    "- Data exploration and visualization\n",
    "- Data preprocessing\n",
    "- Training multiple models: Logistic Regression, Decision Tree, Random Forest, Support Vector Machine (SVM)\n",
    "- Model evaluation and comparison\n",
    "- Explanation of key classification concepts\n",
    "- Guidance on interpreting results\n",
    "\n",
    "## Classification Concepts\n",
    "\n",
    "- **Classification**: Predicting a categorical label (here: iris species) from input features.\n",
    "- **Training/Test Split**: We split our data so the model can be trained and then tested on unseen data, which helps estimate real-world performance.\n",
    "- **Accuracy**: Percentage of correct predictions on the test set.\n",
    "- **Confusion Matrix**: Shows how often each class is correctly or incorrectly predicted.\n",
    "- **Precision, Recall, F1-score**: Evaluate model quality for each class. High values mean good predictions. F1-score balances precision and recall.\n",
    "- **Cross-validation**: More robust evaluation using multiple train/test splits.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Iris.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Species'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is well-balanced with 50 samples per species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values are found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot to visualize feature distributions by species\n",
    "sns.pairplot(df.drop('Id', axis=1), hue='Species', diag_kind='hist')\n",
    "plt.suptitle('Pairplot of Iris Features by Species', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature correlation heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(df.drop(['Id', 'Species'], axis=1).corr(), annot=True, cmap='Blues')\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "- Petal measurements show strong correlation with species, making them good predictors.\n",
    "- Sepal measurements show less separation between classes.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing\n",
    "- Select features and target\n",
    "- Encode target labels\n",
    "- Split data\n",
    "- Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target\n",
    "X = df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
    "y = df['Species']\n",
    "\n",
    "# Encode target labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f'Training samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train and Evaluate Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=200),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM (RBF kernel)': SVC(kernel='rbf', probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    if 'SVM' in name or 'Logistic' in name:\n",
    "        # Use scaled features for SVM and Logistic Regression\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        X_eval = X_test_scaled\n",
    "    else:\n",
    "        # Tree-based models don't need scaling\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        X_eval = X_test\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results[name] = {'model': model, 'accuracy': acc, 'y_pred': y_pred, 'X_eval': X_eval}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare Model Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, res in results.items():\n",
    "    print(f'{name}: Accuracy = {res[\"accuracy\"]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All models achieve high accuracy (>0.93) on this well-separated dataset.\n",
    "- SVM and Random Forest often perform best on small, non-linear, or complex datasets.\n",
    "- Logistic Regression is simple and interpretable, Decision Trees are explainable, Random Forests and SVMs are usually more robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Detailed Evaluation: Confusion Matrix and Classification Report\n",
    "Let's look at the best model (highest accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best model\n",
    "best_name = max(results, key=lambda k: results[k]['accuracy'])\n",
    "best_res = results[best_name]\n",
    "print(f'Best Model: {best_name} (Accuracy: {best_res[\"accuracy\"]:.3f})')\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, best_res['y_pred'])\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(f'Confusion Matrix: {best_name}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test, best_res['y_pred'], target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guidance on Results Interpretation\n",
    "- **Accuracy**: Percentage of total correct predictions. High accuracy here means the model rarely misclassifies the species.\n",
    "- **Confusion Matrix**: Diagonal values (top-left to bottom-right) are correctly classified samples for each class. Off-diagonal values show misclassifications.\n",
    "- **Precision**: Of all predicted instances of a class, how many were correct?\n",
    "- **Recall**: Of all actual instances of a class, how many did we correctly predict?\n",
    "- **F1-score**: Harmonic mean of precision and recall. Best if close to 1.\n",
    "- **Interpretation**: All classes are well separated; metrics close to 1.0 indicate excellent performance.\n",
    "\n",
    "> On real-world data or less-separated datasets, you'd want to check for class imbalance, overfitting, and generalization using cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Test Predictions\n",
    "Scatter plot for petal features with predicted species colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualization, use true test values\n",
    "plt.figure(figsize=(8,6))\n",
    "scatter = plt.scatter(X_test['PetalLengthCm'], X_test['PetalWidthCm'], c=best_res['y_pred'], cmap='viridis', s=60, edgecolor='k')\n",
    "plt.xlabel('Petal Length (cm)')\n",
    "plt.ylabel('Petal Width (cm)')\n",
    "plt.title(f'Test Set Predictions: {best_name}')\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=le.classes_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cross-Validation (Bonus: Robust Performance Estimate)\n",
    "Cross-validation helps estimate how well the model will generalize to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(best_res['model'], scaler.transform(X), y_encoded, cv=5)\n",
    "print(f'Cross-Validation Accuracy (mean ± std): {cv_scores.mean():.3f} ± {cv_scores.std():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "- Used multiple models (Logistic Regression, Decision Tree, Random Forest, SVM)\n",
    "- All models performed extremely well due to clear class separation in the data\n",
    "- SVM/Random Forest are robust for more complex datasets\n",
    "- Classification metrics confirm very high model quality\n",
    "- Cross-validation supports generalization\n",
    "\n",
    "### Next Steps\n",
    "- Try hyperparameter tuning\n",
    "- Explore feature importance (Random Forest)\n",
    "- Test on new data\n",
    "- Share your notebook and results on GitHub!\n",
    "\n",
    "---\n",
    "## References\n",
    "- [Scikit-learn Classification User Guide](https://scikit-learn.org/stable/supervised_learning.html)\n",
    "- [Iris Dataset Info](https://en.wikipedia.org/wiki/Iris_flower_data_set)\n",
    "---\n",
    "### Happy Data Science!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
